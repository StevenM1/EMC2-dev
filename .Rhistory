n_trials_cog <- 100
n_timepoints_mri <- 100
n_factors <- 2
pars1 <- c("v1", "a", "v2", "t0")
pars2 <- c("MRI_c1", "MRI_c2", "MRI_sd")
group_means <- c(.5, log(1.2), 1, log(0.25), -.3, .5, log(.3)) #a, t0 and neural sd are estimated on log-scale to have support on the natural scale
group_factors <- matrix(c(.4, 0.3,
-.4, .4,
.35, -0.05,
.05, 0.1,
.45, -.05,
.4, -.2,
.1, .25), ncol = n_factors, byrow = T)
rownames(group_factors) <- c(pars1, pars2)
group_resid_variance <- c(.05, .1, .15, .2, .15, .1, .05)
group_cov <- group_factors %*% t(group_factors) + diag(group_resid_variance)
# Inspect our simulated factors
corrplot::corrplot(group_factors, is.corr = F, col.lim = c(-1,1))
# Inspect our simulated correlations matrix
corrplot::corrplot(cov2cor(group_cov), is.corr = T)
# seems reasonable, now make some random effects
random_effects <- mvtnorm::rmvnorm(n_subjects, group_means, group_cov)
colnames(random_effects) <- c(pars1, pars2)
behav_data <- data.frame()
neural_data <- data.frame()
for(sub in 1:n_subjects){
pars_cog <- random_effects[sub,1:4]
pars_mri <- random_effects[sub,5:7]
# Generate 2 difficulty conditions
behav1 <- rtdists::rdiffusion(n_trials_cog/2, a = exp(pars_cog[2]), t0 = exp(pars_cog[4]),
v = pars_cog[1])
behav1$cond <- 1
behav2 <- rtdists::rdiffusion(n_trials_cog/2, a = exp(pars_cog[2]), t0 = exp(pars_cog[4]),
v = pars_cog[3])
behav2$cond <- 2
behav <- rbind(behav1, behav2)
behav$subjects <- sub
behav_data <- rbind(behav_data, behav)
# Just generate some random neural time signal
time_signal <-  mvtnorm::rmvnorm(n_timepoints_mri, mean = rep(0, 2))
BOLD <- rnorm(n_timepoints_mri, mean =
time_signal %*% pars_mri[1:2], sd = exp(pars_mri[3]))
neural <- data.frame(y = BOLD, X = time_signal, subjects = sub)
neural_data <- rbind(neural_data, neural)
}
design1 <- make_design(model = ll_cog, custom_p_vector = pars1)
design2 <- make_design(model = ll_MRI, custom_p_vector = pars2)
samplers <- make_samplers(list(behav_data, neural_data), list(design1, design2), type = "infnt_factor", n_factors = 2)
samplers <- run_emc(samplers, fileName = "test_toy_neural2.RData", cores_per_chain = 4, cores_for_chains = 3, verbose = T, iter = 1000)
getwd()
samplers <- make_samplers(list(behav_data), list(design1), type = "single")
samplers <- run_emc(samplers, fileName = "test_toy_behav2.RData", cores_per_chain = 4, cores_for_chains = 3, verbose = T, iter = 1000)
save(behav_data, neural_data, file = "data_toy2.RData")
samplers <- make_samplers(list(neural_data), list(design2), type = "single")
samplers <- run_emc(samplers, fileName = "test_toy_neural2.RData", cores_per_chain = 4, cores_for_chains = 3, verbose = T, iter = 1000)
plot_chains(samplers)
plot_chains(samplers, selection = "mu")
plot_chains(samplers, subject = 1)
load("~/Documents/UVA/2022/EMC2/test_toy_neural2.RData")
load("~/Documents/UVA/2023/test_toy_neural2.RData")
load("~/Documents/UVA/2023/test_toy_behav2.RData")
samples_behav <- merge_samples(samplers)
load("~/Documents/UVA/2023/test_toy_neural2.RData")
samples_neural <- merge_samples(samplers)
load("~/Documents/UVA/2023/test_toy_behav2.RData")
samples_behav <- merge_samples(samplers)
samples_neural <- samples_neural$samples$alpha[,,samples_neural$samples$stage == "sample"]
samples_behav <- samples_behav$samples$alpha[,,samples_behav$samples$stage == "sample"]
samples <- array(0, dim = c(7, n_subjects, min(dim(samples_neural)[3], dim(samples_behav)[3])))
for(i in 1:3000){
samples[1:4,,i] <- samples_behav[,,i]
samples[5:7,,i] <- samples_neural[,,i]
}
i
N <- min(dim(samples_neural)[3], dim(samples_behav)[3])
samples <- array(0, dim = c(7, n_subjects, N))
for(i in 1:N){
samples[1:4,,i] <- samples_behav[,,i]
samples[5:7,,i] <- samples_neural[,,i]
}
rownames(samples) <- c(rownames(samples_behav), rownames(samples_neural))
devtools::load_all("~/Documents/UVA/2022/EMC2/")
test <- run_hyper(type = "infnt_factor", data = samples, n_factors = 2)
samples <- test
idx <- which(samples$samples$stage == "sample")
n_thin <- 4
n_chain <- length(idx)/3
idx <- idx[rep(rep(c(F, rep(T, n_thin - 1)), each = c(n_chain/n_thin)), 3)]
max_factors <- 2
loadings_recov <- aperm(samples$samples$theta_lambda[,1:max_factors,idx, drop = F], c(2,1,3))
lambda_mcmc <- t(matrix(loadings_recov, prod(dim(loadings_recov)[1:2]), dim(loadings_recov)[3]))
expanded <- expand.grid(1:max_factors, 1:(samples$n_pars - sum(samples$nuisance)))
colnames(lambda_mcmc) <- paste0("LambdaV", expanded[,2], "_", expanded[,1])
setwd("~/Documents/UVA/2023")
source("rsp_parallel_new.R")
library(factor.switching)
res_merged <- rsp_mc(lambda_mcmc, n_cores = 5)
plot(res_merged)
load("~/Documents/UVA/2023/test_toy_2.RData")
load("~/Documents/UVA/2023/test_toy_2.RData")
samples <- merge_samples(samplers)
idx <- which(samples$samples$stage == "sample")
n_thin <- 4
n_chain <- length(idx)/3
idx <- idx[rep(rep(c(F, rep(T, n_thin - 1)), each = c(n_chain/n_thin)), 3)]
max_factors <- 2
loadings_recov <- aperm(samples$samples$theta_lambda[,1:max_factors,idx, drop = F], c(2,1,3))
lambda_mcmc <- t(matrix(loadings_recov, prod(dim(loadings_recov)[1:2]), dim(loadings_recov)[3]))
expanded <- expand.grid(1:max_factors, 1:(samples$n_pars - sum(samples$nuisance)))
colnames(lambda_mcmc) <- paste0("LambdaV", expanded[,2], "_", expanded[,1])
setwd("~/Documents/UVA/2023")
source("rsp_parallel_new.R")
library(factor.switching)
res <- rsp_mc(lambda_mcmc, n_cores = 5)
plot(res)
res$lambda_hat
res_merged$lambda_hat
varimax(group_factors, F)$loadings[,]
make_hists <- function(hyper, non_hyper, true, title = "Loadings"){
hyper_df <- data.frame(values = hyper, iteration = 1:length(hyper), name = "joint")
non_hyper_df <- data.frame(values = non_hyper, iteration = 1:length(non_hyper), name = "non-joint")
colnames(hyper_df) <- c("values", "iteration", "name")
colnames(non_hyper_df) <- c("values", "iteration", "name")
true_df <- data.frame(values = true, iteration = 1, name = "true")
df <- rbind(hyper_df, non_hyper_df, true_df)
p <- ggplot(df, aes(values)) +
geom_density(data = subset(df, name %in% c("joint", "non-joint")), aes(fill=name), alpha = .25)+
geom_vline(data = subset(df, !name %in% c("joint", "non-joint")), aes(xintercept = values), colour = "black", linewidth = 1.25, lty = "11") +
ggtitle(title)+
theme_bw()
plot(p)
}
n_pars <- 7
idx <- 1:nrow(res$lambda_reordered_mcmc)
lambda_reordered <- array(0, dim = c(n_pars, max_factors, length(idx)))
for(i in 1:length(idx)){
lambda_reordered[,,i] <- matrix(res$lambda_reordered_mcmc[i,], nrow = n_pars, byrow = T)
}
idx <- 1:nrow(res_merged$lambda_reordered_mcmc)
lambda_reordered_merged <- array(0, dim = c(n_pars, max_factors, length(idx)))
for(i in 1:length(idx)){
lambda_reordered_merged[,,i] <- matrix(res_merged$lambda_reordered_mcmc[i,], nrow = n_pars, byrow = T)
}
res$lambda_hat
res_merged$lambda_hat
varimax(group_factors, F)$loadings[,]
lambda_reordered_merged <- lambda_reordered_merged[,c(2,1),]
vari_lambda <- varimax(group_factors, F)$loadings[,]
library(ggplot2)
R <- 2
C <- 2
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
means <- res$lambda_hat
means_merged <- res_merged$lambda_hat[,c(2,1)]
mean(abs(means-vari_lambda))
mean(abs(means_merged-vari_lambda))
R <- 1
C <- 2
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
R <- 3
C <- 2
make_hists(lambda_reordered[R,C,], lambda_reordered_merged[R,C,], vari_lambda[R,C])
samples_behav
1/samples$samples$theta_sig_err_inv
1/samples$samples$theta_sig_err_inv[1,]
# Sig err inv
load("~/Documents/UVA/2023/test_toy_neural2.RData")
samples_neural <- merge_samples(samplers)
load("~/Documents/UVA/2023/test_toy_behav2.RData")
samples_behav <- merge_samples(samplers)
load("~/Documents/UVA/2023/test_toy_2.RData")
samples <- merge_samples(samplers)
sig_behav <- samples_behav$samples$theta_sig_err_inv[,samples$samples$stage == "sample"]
sig_behav <- samples_behav$samples$theta_sig_err_inv[,samples_behav$samples$stage == "sample"]
make_hists(sig_full[1,], sig_behav[1,], group_resid_variance)
sig_full <- samples$samples$theta_sig_err_inv[,samples$samples$stage == "sample"]
sig_behav <- samples_behav$samples$theta_sig_err_inv[,samples_behav$samples$stage == "sample"]
make_hists(sig_full[1,], sig_behav[1,], group_resid_variance)
sig_full[1,]
1/sig_behav[1,]
sig_full <- samples$samples$theta_sig_err_inv[,samples$samples$stage == "sample"]
sig_merged <- test$samples$theta_sig_err_inv
make_hists(1/sig_full[1,], 1/sig_merged[1,], group_resid_variance)
make_hists(1/sig_full[1,], 1/sig_merged[1,], group_resid_variance[1])
N <- 1
make_hists(1/sig_full[N,], 1/sig_merged[N,], group_resid_variance[N])
N <- 2
make_hists(1/sig_full[N,], 1/sig_merged[N,], group_resid_variance[N])
N <- 3
make_hists(1/sig_full[N,], 1/sig_merged[N,], group_resid_variance[N])
N <- 4
make_hists(1/sig_full[N,], 1/sig_merged[N,], group_resid_variance[N])
N <- 5
make_hists(1/sig_full[N,], 1/sig_merged[N,], group_resid_variance[N])
N <- 6
make_hists(1/sig_full[N,], 1/sig_merged[N,], group_resid_variance[N])
N <- 7
make_hists(1/sig_full[N,], 1/sig_merged[N,], group_resid_variance[N])
>>>>>>> upstream/main
NULL[1,]
rm(list=ls())
devtools::load_all()
print(load("test_files/PNAS.RData"))
dat <- data[,c("s","E","S","R","RT")]
names(dat)[c(1,5)] <- c("subjects","rt")
levels(dat$R) <- levels(dat$S)
head(dat)
# NB: This data has been truncated at 0.25s and 1.5s
# Average rate = intercept, and rate d = difference (match-mismatch) contrast
ADmat <- matrix(c(-1/2,1/2),ncol=1,dimnames=list(NULL,"d"))
ADmat
Emat <- matrix(c(0,-1,0,0,0,-1),nrow=3)
dimnames(Emat) <- list(NULL,c("a-n","a-s"))
Emat
# Here we fit a series of models
# We'll first build several plausible models and then do model selection
# Only B affected by E
design_B <- make_design(
Ffactors=list(subjects=levels(dat$subjects),S=levels(dat$S),E=levels(dat$E)),
Rlevels=levels(dat$R),matchfun=function(d)d$S==d$lR,
Flist=list(v~lM,sv~1,B~E,A~1,t0~1),
constants=c(sv=log(1)),
model=lbaB)
# prior <- get_prior_single(design = design_B)
# plot_prior(prior)
prior <- list(
theta_mu_mean = 1:5,
theta_mu_var = diag(c(5:1))
) # This way we're using default priors for the nuisance parameters
dat2 <- dat[dat$subjects %in% unique(dat$subjects)[1:4],]
dat2$subjects <- droplevels(dat2$subjects)
# Nuisance non hyper = non hierarchically estimated parameters
devtools::load_all()
debug(make_samplers)
samplers <- make_samplers(dat2, design_B, type = "standard")
rm(list=ls())
devtools::load_all()
print(load("test_files/PNAS.RData"))
dat <- data[,c("s","E","S","R","RT")]
names(dat)[c(1,5)] <- c("subjects","rt")
levels(dat$R) <- levels(dat$S)
head(dat)
# NB: This data has been truncated at 0.25s and 1.5s
# Average rate = intercept, and rate d = difference (match-mismatch) contrast
ADmat <- matrix(c(-1/2,1/2),ncol=1,dimnames=list(NULL,"d"))
ADmat
Emat <- matrix(c(0,-1,0,0,0,-1),nrow=3)
dimnames(Emat) <- list(NULL,c("a-n","a-s"))
Emat
# Here we fit a series of models
# We'll first build several plausible models and then do model selection
# Only B affected by E
design_B <- make_design(
Ffactors=list(subjects=levels(dat$subjects),S=levels(dat$S),E=levels(dat$E)),
Rlevels=levels(dat$R),matchfun=function(d)d$S==d$lR,
Flist=list(v~lM,sv~1,B~E,A~1,t0~1),
constants=c(sv=log(1)),
model=lbaB)
# prior <- get_prior_single(design = design_B)
# plot_prior(prior)
prior <- list(
theta_mu_mean = 1:5,
theta_mu_var = diag(c(5:1))
) # This way we're using default priors for the nuisance parameters
dat2 <- dat[dat$subjects %in% unique(dat$subjects)[1:4],]
dat2$subjects <- droplevels(dat2$subjects)
# Nuisance non hyper = non hierarchically estimated parameters
devtools::load_all()
debug(make_samplers)
samplers <- make_samplers(dat2, design_B, type = "standard")
prior
rm(list=ls())
devtools::load_all()
print(load("test_files/PNAS.RData"))
dat <- data[,c("s","E","S","R","RT")]
names(dat)[c(1,5)] <- c("subjects","rt")
levels(dat$R) <- levels(dat$S)
head(dat)
# NB: This data has been truncated at 0.25s and 1.5s
# Average rate = intercept, and rate d = difference (match-mismatch) contrast
ADmat <- matrix(c(-1/2,1/2),ncol=1,dimnames=list(NULL,"d"))
ADmat
Emat <- matrix(c(0,-1,0,0,0,-1),nrow=3)
dimnames(Emat) <- list(NULL,c("a-n","a-s"))
Emat
# Here we fit a series of models
# We'll first build several plausible models and then do model selection
# Only B affected by E
design_B <- make_design(
Ffactors=list(subjects=levels(dat$subjects),S=levels(dat$S),E=levels(dat$E)),
Rlevels=levels(dat$R),matchfun=function(d)d$S==d$lR,
Flist=list(v~lM,sv~1,B~E,A~1,t0~1),
constants=c(sv=log(1)),
model=lbaB)
# prior <- get_prior_single(design = design_B)
# plot_prior(prior)
prior <- list(
theta_mu_mean = 1:5,
theta_mu_var = diag(c(5:1))
) # This way we're using default priors for the nuisance parameters
dat2 <- dat[dat$subjects %in% unique(dat$subjects)[1:4],]
dat2$subjects <- droplevels(dat2$subjects)
# Nuisance non hyper = non hierarchically estimated parameters
devtools::load_all()
debug(make_samplers)
samplers <- make_samplers(dat2, design_B, type = "standard")
rm(list=ls())
devtools::load_all()
print(load("test_files/PNAS.RData"))
dat <- data[,c("s","E","S","R","RT")]
names(dat)[c(1,5)] <- c("subjects","rt")
levels(dat$R) <- levels(dat$S)
head(dat)
# NB: This data has been truncated at 0.25s and 1.5s
# Average rate = intercept, and rate d = difference (match-mismatch) contrast
ADmat <- matrix(c(-1/2,1/2),ncol=1,dimnames=list(NULL,"d"))
ADmat
Emat <- matrix(c(0,-1,0,0,0,-1),nrow=3)
dimnames(Emat) <- list(NULL,c("a-n","a-s"))
Emat
# Here we fit a series of models
# We'll first build several plausible models and then do model selection
# Only B affected by E
design_B <- make_design(
Ffactors=list(subjects=levels(dat$subjects),S=levels(dat$S),E=levels(dat$E)),
Rlevels=levels(dat$R),matchfun=function(d)d$S==d$lR,
Flist=list(v~lM,sv~1,B~E,A~1,t0~1),
constants=c(sv=log(1)),
model=lbaB)
# prior <- get_prior_single(design = design_B)
# plot_prior(prior)
prior <- list(
theta_mu_mean = 1:5,
theta_mu_var = diag(c(5:1))
) # This way we're using default priors for the nuisance parameters
dat2 <- dat[dat$subjects %in% unique(dat$subjects)[1:4],]
dat2$subjects <- droplevels(dat2$subjects)
# Nuisance non hyper = non hierarchically estimated parameters
devtools::load_all()
debug(make_samplers)
samplers <- make_samplers(dat2, design_B, type = "standard")
debug(pmwgs)
debug(extractDadms)
dadms[[1]]
attr(dadms[[1]], "sampled_p_names")
attr(dadms[[1]], "model")()$log_likelihood
rm(list=ls())
devtools::load_all()
print(load("test_files/PNAS.RData"))
dat <- data[,c("s","E","S","R","RT")]
names(dat)[c(1,5)] <- c("subjects","rt")
levels(dat$R) <- levels(dat$S)
head(dat)
# NB: This data has been truncated at 0.25s and 1.5s
# Average rate = intercept, and rate d = difference (match-mismatch) contrast
ADmat <- matrix(c(-1/2,1/2),ncol=1,dimnames=list(NULL,"d"))
ADmat
Emat <- matrix(c(0,-1,0,0,0,-1),nrow=3)
dimnames(Emat) <- list(NULL,c("a-n","a-s"))
Emat
# Here we fit a series of models
# We'll first build several plausible models and then do model selection
# Only B affected by E
design_B <- make_design(
Ffactors=list(subjects=levels(dat$subjects),S=levels(dat$S),E=levels(dat$E)),
Rlevels=levels(dat$R),matchfun=function(d)d$S==d$lR,
Flist=list(v~lM,sv~1,B~E,A~1,t0~1),
constants=c(sv=log(1)),
model=lbaB)
# prior <- get_prior_single(design = design_B)
# plot_prior(prior)
prior <- list(
theta_mu_mean = 1:7,
theta_mu_var = diag(c(7:1))
) # This way we're using default priors for the nuisance parameters
dat2 <- dat[dat$subjects %in% unique(dat$subjects)[1:4],]
dat2$subjects <- droplevels(dat2$subjects)
# Nuisance non hyper = non hierarchically estimated parameters
devtools::load_all()
debug(make_samplers)
samplers <- make_samplers(dat2, design_B, type = "standard", prior = prior)
samplers <- run_emc(samplers, verbose = T, cores_for_chains = 4, cores_per_chain = 3)
undebug(make_samplers)
samplers <- make_samplers(dat2, design_B, type = "standard", prior = prior)
samplers[[1]]$prior
load("~/Documents/UVA/2023/SummerSchool/data_ajh.RData")
# Format the data to be suitable for analysis by the EMC2 package.
dat <- data_ajh
names(dat)[1] <- "subjects"
dat <- dat[,c("subjects","S","CI","E","R","rt")]
# There were some fast responses due to double button presses removed by the
# following line (these are all ~50ms which is the measurement resolution of
# the toy experiment written in RStudio).
dat <- dat[dat$rt>.2,-7]
# A design and associated model are specified in EMC2 using the make_design
# function. We will now work through how to specify its its 5 core arguments
# see:
?make_design
# 1) To begin we set up a Wiener diffusion, which is a special case of the "full"
#    diffusion decision model (DDM), by setting some of the parameters of the
#    DDM to constants with this argument:
constants=c(s=log(1),st0=log(0),DP=qnorm(0.5),SZ=qnorm(0),sv=log(0))
# 2) The DDM model is specified with this argument:
model=ddmTZD
# ddmTZD is a function exported by the EMC2 package. The function is for
# internal use so you don't need to understand its structure, but
# if you are curious you can look at it.
ddmTZD
# 3) Two further arguments provide information about the data to be fit. The
# first, Ffactors (factors that can be used in the formula) specifies a list of
# the levels of the factors spanning all of the cells in the data frame to be
# analyzed (i.e., E, CI and S)  which can have any name except for the names
# "R", "rt" and "subjects", which are reserved for columns in the data frame
# giving the response factor (R), a numeric response  time column (rt) and a
# factor column specifying the subjects, with levels  that must also be
# specified in the Ffactors argument. In this case there is  only one subject
Ffactors=list(subjects=levels(dat$subjects),
S=levels(dat$S),CI=levels(dat$CI),E=levels(dat$E))
library(EMC2)
# 1) To begin we set up a Wiener diffusion, which is a special case of the "full"
#    diffusion decision model (DDM), by setting some of the parameters of the
#    DDM to constants with this argument:
constants=c(s=log(1),st0=log(0),DP=qnorm(0.5),SZ=qnorm(0),sv=log(0))
# 2) The DDM model is specified with this argument:
model=ddmTZD
# ddmTZD is a function exported by the EMC2 package. The function is for
# internal use so you don't need to understand its structure, but
# if you are curious you can look at it.
ddmTZD
# 3) Two further arguments provide information about the data to be fit. The
# first, Ffactors (factors that can be used in the formula) specifies a list of
# the levels of the factors spanning all of the cells in the data frame to be
# analyzed (i.e., E, CI and S)  which can have any name except for the names
# "R", "rt" and "subjects", which are reserved for columns in the data frame
# giving the response factor (R), a numeric response  time column (rt) and a
# factor column specifying the subjects, with levels  that must also be
# specified in the Ffactors argument. In this case there is  only one subject
Ffactors=list(subjects=levels(dat$subjects),
S=levels(dat$S),CI=levels(dat$CI),E=levels(dat$E))
# 4) We also separately specify the levels of the response factor in the Rlevels
# (response levels) argument. In more advanced applications this gives EMC2 the
# ability to move beyond binary choice. Note that levels can also be specified
# as character vectors.
Rlevels=levels(dat$R)
#    incongruent stimuli (v_Sleft:CIincongruent and v_Sright:CIincongruent). In
#    both cases we might expect the incongruent rate to be less than the
#    congruent rate, and hence these terms to be positive and negative
#    respectively.
# c) Non-decision time (t0) and response bias (Z, as a proportion of a, so
#    a value of 0.5 is unbiased) that is the same for all conditions.
#
# NB: We have to provide formulas for all 9 of the DDM's parameter types,
#     including the 5 not estimated, but these are ignored in
#     estimation, being always set at the constant values specified above.
Flist=list(a~E,v~0+S/CI,Z~1,t0~1,sv~1,st0~1, s~1, SZ~1, DP~1)
# Load these to get the results of the slower parts of the following analysis
# of data_ajh. You can also substitute in your data and analyse it as well.
print(load("Flanker/FlankerSamples.RData"))
# WDM is a special case of the DDM with between-trial variability set to zero.
constants <- c(st0=log(0),sv=log(0),SZ=qnorm(0),s=log(1),DP=qnorm(0.5))
# Now lets fit the DDM by also estimating the three between-trial variability
# parameters (by removing them from constants).
designDDM <- make_design(model=ddmTZD,Rlevels=levels(dat$R),
Ffactors=list(subjects=levels(dat$subjects),
S=levels(dat$S),CI=levels(dat$CI),E=levels(dat$E)),
Flist=list(a~E,v~0+S/CI,Z~1,t0~1,st0~1,sv~1,SZ~1,s~1, DP~1),
constants=c(s=log(1),DP=qnorm(0.5)))
designRDM <- make_design(
Ffactors=list(subjects=levels(dat$subjects),
S=levels(dat$S),CI=levels(dat$CI),E=levels(dat$E)),
Rlevels=levels(dat$R),matchfun=function(d)d$S==d$lR,
Flist=list(B~E+lR,v~lM*CI,A~1,t0~1,s~1),constants=c(s=log(1),A=log(0)),
Clist=list(lM=ADmat),model=rdmB)
# Race models have one accumulator for each response, each with its own
# parameters. For rates it is useful to recode these parameters in terms of
# the average rate across accumulators (intercept), and rate d = difference
# (match-mismatch) contrast. The latter is analogous to the WDM/DDM rate. The
# intercept is and index of decision urgency and stimulus magnitude effects.
# This re-coding is achieved using a contrast matrix that is supplied to the
# Clist argument of make_design, so we create it here for use in the race
# models created below.
ADmat <- matrix(c(-1/2,1/2),ncol=1,dimnames=list(NULL,"d"))
designRDM <- make_design(
Ffactors=list(subjects=levels(dat$subjects),
S=levels(dat$S),CI=levels(dat$CI),E=levels(dat$E)),
Rlevels=levels(dat$R),matchfun=function(d)d$S==d$lR,
Flist=list(B~E+lR,v~lM*CI,A~1,t0~1,s~1),constants=c(s=log(1),A=log(0)),
Clist=list(lM=ADmat),model=rdmB)
# Priors are based on our informal experience with this model to be
# be reasonable but fairly vague.
theta_mu_mean <- c(B=log(2),B_Espeed=log(1),B_lRright=log(1),v=log(2),
v_lMd=log(2),v_CIincongruent=log(1),'v_lMd:CIincongruent'=log(1),t0=log(.2))
priorRDM <- list(theta_mu_mean  = theta_mu_mean,
theta_mu_var = diag(c(1,.5,.5,1,.5,.5,.5,.5)^2))
# Priors have long tails so use upper argument to truncated at 99th percentile
plot_prior(priorRDM,designRDM,upper=.99,type="single")
# In this model t0 is no longer on a log scale, so we specify a parameter vector
# correspondingly
p_vectort0natural <- c(B=log(2),B_Espeed=log(1),B_lRright=log(1),v=log(2),
v_lMd=log(2),v_CIincongruent=log(1),'v_lMd:CIincongruent'=log(1),
t0=.2,t0_Sright=0.1,t0_Espeed=-0.1)
# EMC2 is supplied with an RDM model that solves this problem rdmBt0natural
designRDMt0natural <- make_design(
Ffactors=list(subjects=levels(dat$subjects),
S=levels(dat$S),CI=levels(dat$CI),E=levels(dat$E)),
Rlevels=levels(dat$R),matchfun=function(d)d$S==d$lR,
Flist=list(B~E+lR,v~lM*CI,A~1,t0~S+E,s~1),constants=c(s=log(1),A=log(0)),
Clist=list(lM=ADmat),model=rdmBt0natural)
# Tof illustrate simulate an effectively "asymptotic") data set, one that is so
# large that sampling noise is at a minimum. The result is 40,000 trials, 5000
# in each of the 8 design cells.
sdat <- make_data(p_vectort0natural,designRDMt0natural,trials=5000)
